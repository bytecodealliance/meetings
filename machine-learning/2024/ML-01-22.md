# Wasm+ML Working Group &mdash; January 22

See the [instructions](../README.md) for details on how to attend.

### Agenda

1. Opening, welcome and roll call
    1. Please help take notes &mdash; thanks!
1. Announcements
    1. _Submit a PR to add your announcement here_
1. Proposals and discussions
    1. Goals for 2024

### Attendees

- Andrew Brown
- Mingqiu Sun
- Hung-Ying Tay (hydai)
- Ayako Akasaka
- Matthew Tamayo-Rios
- David Justice
- Wilson Wang

### Notes

AB: reviewed topics from October 2023 presentation; most are completed. Some remaining (and new)
issues for 2024:
- Model versioning
- Streams
- WebNN compatibility
- New APIs
- Release a wasi-nn version
- Implementation: finish new backends, WIT tooling, resources

HT: interested in streaming back results of LLM computation; don't want to block the process.

MTR: interested in tensor data validation (e.g., f32 vs. always `bytes`)--this could be resolved
either with new APIs or by fixing implementation bugs. Discussed a tension between running large
models on the edge versus a central cloud: long execution times may force these to be cloud-run.

MS: What about running models directly on the user machine?

MTR: There are frameworks out there; some interest but not a direct Fastly problem.

AB: Is streaming a need for the Fastly edge?

MTR: There may be some need for streaming output tensors, but only for LLMs, not classification
results, e.g.

DJ: Like MTR, interested in tensor data validation to improve developer experience--currently, no
compile-time checks, error prone. No generics available so this can only be taken so far, though.

AB: How is the ONNX PR going?

DJ: Still working on PR adding ONNX backend to Wasmtime; would prefer to merge upstream but worried
about failing dependency checks in CI.

WW: We are still in the early stages of experimenting with wasi-nn at ByteDance.

AA: We are interested in WIT resources for tensors but use WAMR--will WAMR support the component
model?

MS: WAMR is waiting to implement CM until users ask for it; let's make this requirement known.

AA: We are also interested in model versioning and more broadly how to check for support of many
features on embedded devices.

AB: Agenda items for next meeting:
- HT: describe use case for streaming tensor results in wasi-nn; i.e., `compute_single` solution
- MTR: describe improvements for tensor data validation--extract applicable part of solution from
  `bytes` discussion
- AA: describe requirements for model versioning; what is needed in the embedded space?

