# Wasm+ML Working Group &mdash; November 11

See the [instructions](../README.md) for details on how to attend.

### Agenda

1. Opening, welcome and roll call
    1. Please help take notes &mdash; thanks!
1. Announcements
    1. _Submit a PR to add your announcement here_
1. Proposals and discussions
    1. Discuss conformance rules; Stuart Schaefer
    1. Discuss language for an "intent to support" issue; Andrew Brown
    1. _Submit a PR to add your announcement here_

### Attendees

- Andrew Brown
- Yunus Basagalar
- Mingqiu Sun
- Johnnie Birch
- Hung-Ying Tai (hydai)
- Wilson Wang
- Ralph Squillace

### Notes

In Stuart's absence we pushed out the discussion of test suite conformance rules to a different
date. We discussed the right language for a "support survey" issue, which is now public: [#83]. This
is the place to indicate support for moving wasi-nn forward in the WASI proposal process.

[#83]: https://github.com/WebAssembly/wasi-nn/issues/83

As a part of this, hydai mentioned several changes WasmEdge has had to make to accommodate LLMs,
most notably the need to stream tokens from an LLM using the not-yet-standard `compute_single`.
Andrew proposed that we could upstream that into the specification as a part of a new `prompt`
interface ([#79]) until preview 3 brings native support for streams. hydai highlighted one
difference &mdash; the `prompt` interface returns strings while `compute_single` returns tokens
&mdash; but indicated this might be resolvable. Ralph indicated the string-based version might be
closer to what developers want (see Fermyon's [Serverless AI API])

[#79]: https://github.com/WebAssembly/wasi-nn/pull/79
[Serverless AI API]: https://developer.fermyon.com/spin/v2/serverless-ai-api-guide

Along these lines, we also discussed how to configure LLM execution. hydai mentioned that WasmEdge
currently has a `finalize` function to tell the LLM to stop sending tokens. Andrew mentioned that
Fermyon's API passes a list of parameters; [#80] is a way to configure wasi-nn graphs in this way.
Yunus pointed out that that PR's "string to string" mapping allows for incorrect usage of the API
(e.g., when passing nonsense configuration). Andrew mentioned a trade-off: LLM configuration is
likely to change in the future and deciding now on the configuration could limit us in the future.
Ralph suggested we leave the "string to string" mapping for now until we have more implementation
feedback.

[#80]: https://github.com/WebAssembly/wasi-nn/pull/80
